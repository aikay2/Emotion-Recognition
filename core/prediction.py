# import tensorflow as tf
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing import image
# import numpy as np
# import os

# # Load the trained model once when the server starts
# MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'face_emotionModel.h5')
# model = load_model(MODEL_PATH)

# # Define the same class order you trained with
# class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']

# def predict_emotion(img_path):
#     """Takes an image path and returns the detected emotion label"""
#     img = image.load_img(img_path, target_size=(224, 224))
#     img_array = image.img_to_array(img) / 255.0
#     img_array = np.expand_dims(img_array, axis=0)
#     prediction = model.predict(img_array)
#     predicted_class = np.argmax(prediction)
#     return class_names[predicted_class]

# def map_to_message(emotion):
#     """Maps emotion to a friendly message and emoji"""
#     messages = {
#         "angry": ("Take a deep breath! Itâ€™s okay to feel angry sometimes.", "ğŸ˜ "),
#         "disgust": ("Yikes! Something clearly didnâ€™t sit right.", "ğŸ¤¢"),
#         "fear": ("Donâ€™t worry, youâ€™re safe here.", "ğŸ˜¨"),
#         "happy": ("Keep smiling! The world shines brighter with you.", "ğŸ˜„"),
#         "neutral": ("Nice and calm â€” balanced vibes.", "ğŸ˜"),
#         "sad": ("Itâ€™s okay to feel sad. Brighter days are ahead.", "ğŸ˜¢"),
#         "surprise": ("Whoa! Didnâ€™t see that coming, huh?", "ğŸ˜²"),
#         "error": ("Error detecting emotion. Please try again.", "âš ï¸")
#     }
#     return messages.get(emotion, ("Unknown emotion", "â“"))

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image

# Locate the TensorFlow Lite model inside 'core' folder
MODEL_PATH = os.path.join(os.path.dirname(__file__), 'face_emotionModel_quant.tflite')

# Global interpreter (cached so it doesn't reload on every request)
_interpreter = None
_input_details = None
_output_details = None


def get_interpreter():
    global _interpreter, _input_details, _output_details
    if _interpreter is None:
        _interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)
        _interpreter.allocate_tensors()
        _input_details = _interpreter.get_input_details()
        _output_details = _interpreter.get_output_details()
    return _interpreter, _input_details, _output_details


def predict_emotion(img_path):
    interpreter, input_details, output_details = get_interpreter()

    # Preprocess image
    img = image.load_img(img_path, target_size=(48, 48), color_mode="grayscale")
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array.astype(np.float32) / 255.0

    # Set input tensor
    interpreter.set_tensor(input_details[0]['index'], img_array)

    # Run inference
    interpreter.invoke()

    # Get output tensor
    prediction = interpreter.get_tensor(output_details[0]['index'])
    emotion_index = int(np.argmax(prediction))
    return ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'][emotion_index]


def map_to_message(emotion):
    messages = {
        'angry': ("Try to stay calm, youâ€™ve got this!", "ğŸ˜¡"),
        'disgust': ("Maybe step away for a bit.", "ğŸ¤¢"),
        'fear': ("Itâ€™s okay to be scared sometimes.", "ğŸ˜¨"),
        'happy': ("Keep smiling! The world needs more of that!", "ğŸ˜„"),
        'neutral': ("Steady and composed. Nice balance!", "ğŸ˜"),
        'sad': ("Cheer up â€” better days are ahead.", "ğŸ˜¢"),
        'surprise': ("Wow! Didnâ€™t see that coming!", "ğŸ˜²"),
    }
    return messages.get(emotion, ("Emotion not recognized", "â“"))

